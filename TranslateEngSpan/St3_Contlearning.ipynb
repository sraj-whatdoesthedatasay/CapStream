{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook is to enable multiple epoch runs since the model needed over 50+ epoch runs.  So the model had to be stored and picked up again for more training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "# Visualization library\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP library\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settign same seed to continue with similar model build\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder training setup (coming from the initial model run)\n",
    "num_encoder_tokens = 5044\n",
    "num_decoder_tokens = 8089\n",
    "\n",
    "max_encoder_seq_length = 8\n",
    "max_decoder_seq_length = 17\n",
    "\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>eng</th>\n",
       "      <th>spa</th>\n",
       "      <th>eng_len</th>\n",
       "      <th>spa_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15828</td>\n",
       "      <td>a dog has four legs</td>\n",
       "      <td>un perro tiene cuatro patas</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15829</td>\n",
       "      <td>a lion is an animal</td>\n",
       "      <td>un león es un animal</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15830</td>\n",
       "      <td>a noise woke her up</td>\n",
       "      <td>un ruido la despertó</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15831</td>\n",
       "      <td>a nurse wears white</td>\n",
       "      <td>una enfermera se viste de blanco</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15832</td>\n",
       "      <td>a truck hit the dog</td>\n",
       "      <td>un camión atropelló al perro</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  eng                               spa  eng_len  \\\n",
       "0       15828  a dog has four legs       un perro tiene cuatro patas       19   \n",
       "1       15829  a lion is an animal              un león es un animal       19   \n",
       "2       15830  a noise woke her up              un ruido la despertó       19   \n",
       "3       15831  a nurse wears white  una enfermera se viste de blanco       19   \n",
       "4       15832  a truck hit the dog      un camión atropelló al perro       19   \n",
       "\n",
       "   spa_len  \n",
       "0       27  \n",
       "1       20  \n",
       "2       20  \n",
       "3       32  \n",
       "4       28  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('./data/EngSpa.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>spa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a dog has four legs</td>\n",
       "      <td>un perro tiene cuatro patas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a lion is an animal</td>\n",
       "      <td>un león es un animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a noise woke her up</td>\n",
       "      <td>un ruido la despertó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a nurse wears white</td>\n",
       "      <td>una enfermera se viste de blanco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a truck hit the dog</td>\n",
       "      <td>un camión atropelló al perro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   eng                               spa\n",
       "0  a dog has four legs       un perro tiene cuatro patas\n",
       "1  a lion is an animal              un león es un animal\n",
       "2  a noise woke her up              un ruido la despertó\n",
       "3  a nurse wears white  una enfermera se viste de blanco\n",
       "4  a truck hit the dog      un camión atropelló al perro"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['Unnamed: 0', 'eng_len', 'spa_len'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a bird has wings', 'los pájaros tienen alas'],\n",
       " ['a bird has wings', 'un pájaro tiene alas'],\n",
       " ['a cab is waiting', 'hay un taxi esperando'],\n",
       " ['a deal is a deal', 'un trato es un trato'],\n",
       " ['a dog is barking', 'un perro está ladrando'],\n",
       " ['a fox came along', 'un zorro se acercó'],\n",
       " ['a girl phoned me', 'una chica me llamó por teléfono'],\n",
       " ['a lion is strong', 'el león es fuerte']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting dataframe to list of lists so it can be used for model building\n",
    "data = df.values.tolist()\n",
    "\n",
    "# Examining the first 5 rows\n",
    "data[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building empty lists to hold sentences\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "# Building empty vocabulary sets\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "# Setting the amount of data points to use\n",
    "n = 17500\n",
    "\n",
    "for line in data[:n]:\n",
    "    # Defining an input document and a target document\n",
    "    input_doc, target_doc = line[0], line[1]\n",
    "    \n",
    "    # Appending each input sentence to input_docs\n",
    "    input_docs.append(input_doc)\n",
    "    \n",
    "    # Formatting target documents\n",
    "    # Splitting words from punctuation  \n",
    "    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "    # Adding <START> and <END> tags\n",
    "    target_doc = '<START> ' + target_doc + ' <END>'\n",
    "    # Appending each formated target to target documents\n",
    "    target_docs.append(target_doc)\n",
    "  \n",
    "    # Splitting each sentence into words and adding to vocabulary\n",
    "    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "        if token not in input_tokens:\n",
    "            input_tokens.add(token)\n",
    "    \n",
    "    for token in target_doc.split():\n",
    "        if token not in target_tokens:\n",
    "            target_tokens.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a bird has wings\n",
      "<START> los pájaros tienen alas <END>\n"
     ]
    }
   ],
   "source": [
    "print(input_docs[0])\n",
    "print(target_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dictionaries that were built in Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "with open('./data/rtfd.p', 'rb') as fp:\n",
    "    reverse_target_features_dict = pickle.load(fp)\n",
    "    \n",
    "with open('./data/tfd.p', 'rb') as fp:\n",
    "    target_features_dict = pickle.load(fp)\n",
    "    \n",
    "with open('./data/rifd.p', 'rb') as fp:\n",
    "    reverse_input_features_dict = pickle.load(fp)\n",
    "\n",
    "with open('./data/ifd.p', 'rb') as fp:\n",
    "    input_features_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty matricies for input data\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code sets up our data for input to the neural net using the dictionary input\n",
    "\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "        # Assigning 1.0 for the current line, timestep, & word in encoder_input_data:\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.0\n",
    "        # Potential Conditional Statement\n",
    "\n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "        # Assigning 1.0 for same in decoder_input_data\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.0\n",
    "        if timestep > 0:\n",
    "            \n",
    "            # Setting the decoder target data for 1 previous timestep\n",
    "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "training_model = load_model('endspan15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = training_model.input[0] #input1\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output #lstm1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "## NEW\n",
    "decoder_inputs = training_model.input[1] #input2\n",
    "\n",
    "##\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "\n",
    "## NEW\n",
    "decoder_lstm = training_model.layers[3]\n",
    "##\n",
    "\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "\n",
    "## NEW\n",
    "decoder_dense = training_model.layers[4]\n",
    "##\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "113/113 [==============================] - 184s 2s/step - loss: 1.0122 - accuracy: 0.8608 - val_loss: 1.6700 - val_accuracy: 0.7980\n"
     ]
    }
   ],
   "source": [
    "#Continue with training\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "model_checkpoint= ModelCheckpoint('endspan{epoch:02d}.h5',period=1,save_weights_only=False)\n",
    "\n",
    "history = training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs, \n",
    "                    callbacks=[model_checkpoint],         \n",
    "                    validation_split = 0.2)\n",
    "                    #callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_matrix(user_input):\n",
    "    '''This function takes in a string and outputs the corresponding matrix'''\n",
    "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "    user_input_matrix = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "    for timestep, token in enumerate(tokens):\n",
    "        if token in input_features_dict:\n",
    "            user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "    return user_input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(test_input):\n",
    "    '''This function takes in a sentence and returns the decoded sentence'''\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(string_to_matrix(test_input))\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first token of target sequence with the start token.\n",
    "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "        # Run the decoder model to get possible output tokens (with probabilities) & states\n",
    "        output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Choose token with highest probability and append it to decoded sentence\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop token.\n",
    "        if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [hidden_state, cell_state]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' qué están de <END>'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example decoded sentence\n",
    "decode_sequence('how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hoy es <END>'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example decoded sentence\n",
    "decode_sequence('it is hot today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' estoy de <END>'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example decoded sentence\n",
    "decode_sequence('i am')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "# Visualization library\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP library\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/EngSpa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>eng</th>\n",
       "      <th>spa</th>\n",
       "      <th>eng_len</th>\n",
       "      <th>spa_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15828</td>\n",
       "      <td>a dog has four legs</td>\n",
       "      <td>un perro tiene cuatro patas</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15829</td>\n",
       "      <td>a lion is an animal</td>\n",
       "      <td>un león es un animal</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15830</td>\n",
       "      <td>a noise woke her up</td>\n",
       "      <td>un ruido la despertó</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15831</td>\n",
       "      <td>a nurse wears white</td>\n",
       "      <td>una enfermera se viste de blanco</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15832</td>\n",
       "      <td>a truck hit the dog</td>\n",
       "      <td>un camión atropelló al perro</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  eng                               spa  eng_len  \\\n",
       "0       15828  a dog has four legs       un perro tiene cuatro patas       19   \n",
       "1       15829  a lion is an animal              un león es un animal       19   \n",
       "2       15830  a noise woke her up              un ruido la despertó       19   \n",
       "3       15831  a nurse wears white  una enfermera se viste de blanco       19   \n",
       "4       15832  a truck hit the dog      un camión atropelló al perro       19   \n",
       "\n",
       "   spa_len  \n",
       "0       27  \n",
       "1       20  \n",
       "2       20  \n",
       "3       32  \n",
       "4       28  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>spa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a dog has four legs</td>\n",
       "      <td>un perro tiene cuatro patas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a lion is an animal</td>\n",
       "      <td>un león es un animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a noise woke her up</td>\n",
       "      <td>un ruido la despertó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a nurse wears white</td>\n",
       "      <td>una enfermera se viste de blanco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a truck hit the dog</td>\n",
       "      <td>un camión atropelló al perro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   eng                               spa\n",
       "0  a dog has four legs       un perro tiene cuatro patas\n",
       "1  a lion is an animal              un león es un animal\n",
       "2  a noise woke her up              un ruido la despertó\n",
       "3  a nurse wears white  una enfermera se viste de blanco\n",
       "4  a truck hit the dog      un camión atropelló al perro"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Unnamed: 0', 'eng_len', 'spa_len'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a dog has four legs', 'un perro tiene cuatro patas'],\n",
       " ['a lion is an animal', 'un león es un animal'],\n",
       " ['a noise woke her up', 'un ruido la despertó'],\n",
       " ['a nurse wears white', 'una enfermera se viste de blanco'],\n",
       " ['a truck hit the dog', 'un camión atropelló al perro']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting to list for the model\n",
    "data = df.values.tolist()\n",
    "\n",
    "# Examining the first 5 rows\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building empty lists to hold sentences\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "# Building empty vocabulary sets\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "# Setting the amount of data points to use\n",
    "n = 15000\n",
    "\n",
    "for line in data[:n]:\n",
    "    # Defining an input document and a target document\n",
    "    input_doc, target_doc = line[0], line[1]\n",
    "    \n",
    "    # Appending each input sentence to input_docs\n",
    "    input_docs.append(input_doc)\n",
    "    \n",
    "    # Formatting target documents\n",
    "    # Splitting words from punctuation  \n",
    "    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "    # Adding <START> and <END> tags\n",
    "    target_doc = '<START> ' + target_doc + ' <END>'\n",
    "    # Appending each formated target to target documents\n",
    "    target_docs.append(target_doc)\n",
    "  \n",
    "    # Splitting each sentence into words and adding to vocabulary\n",
    "    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "        if token not in input_tokens:\n",
    "            input_tokens.add(token)\n",
    "    \n",
    "    for token in target_doc.split():\n",
    "        if token not in target_tokens:\n",
    "            target_tokens.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dog has four legs\n",
      "<START> un perro tiene cuatro patas <END>\n"
     ]
    }
   ],
   "source": [
    "print(input_docs[0])\n",
    "print(target_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sorted list of all input tokens and target tokens\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "# Saving the length of vocabulary sets as variables. Encoder and Decoder\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "# Finding the maximum length of an input sentence and target sentence\n",
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Encoder Tokens: 4693\n",
      "Number of Decoder Tokens: 7391\n",
      "Maximum Encoder Sequence Length: 7\n",
      "Maximum Decoder Sequence Length: 16\n"
     ]
    }
   ],
   "source": [
    "# Print some key dimensions - these need to be used later for enabling model-continued training as well as getting translations\n",
    "print(f'Number of Encoder Tokens: {num_encoder_tokens}')\n",
    "print(f'Number of Decoder Tokens: {num_decoder_tokens}')\n",
    "print(f'Maximum Encoder Sequence Length: {max_encoder_seq_length}')\n",
    "print(f'Maximum Decoder Sequence Length: {max_decoder_seq_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating four dictionaries\n",
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "# Creating the reverse \n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict(\n",
    "    (i, token) for token, i in target_features_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data/rtfd.p', 'wb') as fp:\n",
    "    pickle.dump(reverse_target_features_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/tfd.p', 'wb') as fp:\n",
    "    pickle.dump(target_features_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/rifd.p', 'wb') as fp:\n",
    "    pickle.dump(reverse_input_features_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./data/ifd.p', 'wb') as fp:\n",
    "    pickle.dump(input_features_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'a', 1: 'aback'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking English index and word dictionary\n",
    "first2pairs = {k: reverse_input_features_dict[k] for k in list(reverse_input_features_dict)[:2]}\n",
    "first2pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'aback': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking English word and index dictionary\n",
    "first2pairs = {k: input_features_dict[k] for k in list(input_features_dict)[:2]}\n",
    "first2pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'a',\n",
       " 3: 'abajo',\n",
       " 4: 'abandona',\n",
       " 5: 'abandonada',\n",
       " 6: 'abandonado',\n",
       " 7: 'abandonamos'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Spanish index and word dictionary\n",
    "firstfewpairs = {k: reverse_target_features_dict[k] for k in list(reverse_target_features_dict)[2:8]}\n",
    "firstfewpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2,\n",
       " 'abajo': 3,\n",
       " 'abandona': 4,\n",
       " 'abandonada': 5,\n",
       " 'abandonado': 6,\n",
       " 'abandonamos': 7}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Spanish word and index dictionary\n",
    "firstfewpairs = {k: target_features_dict[k] for k in list(target_features_dict)[2:8]}\n",
    "firstfewpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty matricies for input data\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Input Data Shape: (15000, 7, 4693)\n",
      "Decoder Input Data Shape: (15000, 16, 7391)\n",
      "Decoder Target Data Shape: (15000, 16, 7391)\n"
     ]
    }
   ],
   "source": [
    "print(f'Encoder Input Data Shape: {encoder_input_data.shape}')\n",
    "print(f'Decoder Input Data Shape: {decoder_input_data.shape}')\n",
    "print(f'Decoder Target Data Shape: {decoder_target_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code sets up our data for input to the neural net.\n",
    "\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "        # Assigning 1.0 for the current line, timestep, & word in encoder_input_data:\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.0\n",
    "        # Potential Conditional Statement\n",
    "\n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "        # Assigning 1.0 for same in decoder_input_data\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.0\n",
    "        if timestep > 0:\n",
    "            \n",
    "            # Setting the decoder target data for 1 previous timestep\n",
    "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking sample word in matrix\n",
    "np.argmax(encoder_input_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirming word was read correctly\n",
    "reverse_input_features_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4693 7391 7 16\n"
     ]
    }
   ],
   "source": [
    "print(num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM MODEL BUILD TO START FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Masking\n",
    "from tensorflow.keras.models import Model, save_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.backend import manual_variable_initialization #was added to ensure model can be loaded correctly later\n",
    "manual_variable_initialization(True)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model structure\n",
    "latent_dim = 256 ### Would have liked to increase this, but memory and run-time issues caused me to cap\n",
    "\n",
    "# Encoder training setup\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs) \n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder training setup:\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs,_ ,_ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/5\n",
      "94/94 [==============================] - 178s 2s/step - loss: 2.2564 - accuracy: 0.6855 - val_loss: 2.2001 - val_accuracy: 0.7085\n",
      "Epoch 2/5\n",
      "94/94 [==============================] - 182s 2s/step - loss: 2.0024 - accuracy: 0.7317 - val_loss: 2.2051 - val_accuracy: 0.7088\n",
      "Epoch 3/5\n",
      "94/94 [==============================] - 178s 2s/step - loss: 1.9820 - accuracy: 0.7317 - val_loss: 2.2219 - val_accuracy: 0.7095\n",
      "Epoch 4/5\n",
      "94/94 [==============================] - 148s 2s/step - loss: 1.9654 - accuracy: 0.7317 - val_loss: 2.2060 - val_accuracy: 0.7095\n",
      "Epoch 5/5\n",
      "49/94 [==============>...............] - ETA: 1:03 - loss: 1.9471 - accuracy: 0.7314"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-97bc5d7f608f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./models/endspan{epoch:02d}.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mperiod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m history = training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n\u001b[0m\u001b[0;32m     14\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "#callback = EarlyStopping(monitor='val_accuracy', patience=4) #Was turned off since model was improving gradually\n",
    "\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
    "\n",
    "#Turn checkpoint on so that interim model run results can be used if system crashes, saved every 5 epochs\n",
    "model_checkpoint= ModelCheckpoint('./models/endspan{epoch:02d}.h5',period=5,save_weights_only=False)\n",
    "\n",
    "history = training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs, \n",
    "                    callbacks=[model_checkpoint],         \n",
    "                    validation_split = 0.2)\n",
    "                    #callbacks = callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model so we can use later\n",
    "training_model.save('./models/training_model_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "110/110 [==============================] - 210s 2s/step - loss: 1.8267 - accuracy: 0.7531 - val_loss: 2.0642 - val_accuracy: 0.7345\n",
      "Epoch 2/15\n",
      "110/110 [==============================] - 205s 2s/step - loss: 1.7936 - accuracy: 0.7578 - val_loss: 2.0325 - val_accuracy: 0.7399\n",
      "Epoch 3/15\n",
      "110/110 [==============================] - 208s 2s/step - loss: 1.7630 - accuracy: 0.7620 - val_loss: 2.0236 - val_accuracy: 0.7423\n",
      "Epoch 4/15\n",
      "110/110 [==============================] - 207s 2s/step - loss: 1.7362 - accuracy: 0.7648 - val_loss: 1.9959 - val_accuracy: 0.7431\n",
      "Epoch 5/15\n",
      "110/110 [==============================] - 206s 2s/step - loss: 1.7094 - accuracy: 0.7672 - val_loss: 1.9748 - val_accuracy: 0.7472\n",
      "Epoch 6/15\n",
      "110/110 [==============================] - 211s 2s/step - loss: 1.6820 - accuracy: 0.7706 - val_loss: 1.9661 - val_accuracy: 0.7483\n",
      "Epoch 7/15\n",
      "110/110 [==============================] - 206s 2s/step - loss: 1.6555 - accuracy: 0.7737 - val_loss: 1.9460 - val_accuracy: 0.7505\n",
      "Epoch 8/15\n",
      "110/110 [==============================] - 209s 2s/step - loss: 1.6273 - accuracy: 0.7769 - val_loss: 1.9230 - val_accuracy: 0.7534\n",
      "Epoch 9/15\n",
      "110/110 [==============================] - 222s 2s/step - loss: 1.6002 - accuracy: 0.7810 - val_loss: 1.9151 - val_accuracy: 0.7564\n",
      "Epoch 10/15\n",
      "110/110 [==============================] - 218s 2s/step - loss: 1.5733 - accuracy: 0.7849 - val_loss: 1.8894 - val_accuracy: 0.7599\n",
      "Epoch 11/15\n",
      "110/110 [==============================] - 212s 2s/step - loss: 1.5474 - accuracy: 0.7883 - val_loss: 1.8805 - val_accuracy: 0.7632\n",
      "Epoch 12/15\n",
      "110/110 [==============================] - 222s 2s/step - loss: 1.5221 - accuracy: 0.7913 - val_loss: 1.8675 - val_accuracy: 0.7659\n",
      "Epoch 13/15\n",
      "110/110 [==============================] - 217s 2s/step - loss: 1.4976 - accuracy: 0.7940 - val_loss: 1.8404 - val_accuracy: 0.7672\n",
      "Epoch 14/15\n",
      "110/110 [==============================] - ETA: 0s - loss: 1.4727 - accuracy: 0.7967"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "history2 = training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs, \n",
    "                    callbacks=[model_checkpoint],         \n",
    "                    validation_split = 0.2)\n",
    "                    #callbacks = callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model so we can use later\n",
    "#tf.saved_model.save(training_model, './models/')\n",
    "training_model.save('training_model_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fa47525f12a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.legend()\n",
    "plt.title('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.legend()\n",
    "plt.title('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "training_model = load_model('training_model_v2.h5')\n",
    "\n",
    "encoder_inputs = training_model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "latent_dim = 256\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_matrix(user_input):\n",
    "    '''This function takes in a string and outputs the corresponding matrix'''\n",
    "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "    user_input_matrix = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "    for timestep, token in enumerate(tokens):\n",
    "        if token in input_features_dict:\n",
    "            user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "    return user_input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 4428)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 7675)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 4797440     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  8122368     input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 7675)   1972475     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,892,283\n",
      "Trainable params: 14,892,283\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(test_input):\n",
    "    '''This function takes in a sentence and returns the decoded sentence'''\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(string_to_matrix(test_input))\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first token of target sequence with the start token.\n",
    "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "        # Run the decoder model to get possible output tokens (with probabilities) & states\n",
    "        output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Choose token with highest probability and append it to decoded sentence\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop token.\n",
    "        if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [hidden_state, cell_state]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8395c967cd56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example decoded sentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'how are you'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-283b30a4af5e>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(test_input)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Encode the input as state vectors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mstates_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Generate empty target sequence of length 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoder_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Example decoded sentence\n",
    "decode_sequence('how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hoy es <END>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example decoded sentence\n",
    "decode_sequence('it is hot today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' estoy estoy <END>'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example decoded sentence\n",
    "decode_sequence('i am Shashank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    '''\n",
    "    Utilizing the neural network architecture, this class is to translates English to Spanish. \n",
    "    '''\n",
    "    negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
    "\n",
    "\n",
    "    exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\", 'end')\n",
    "\n",
    "    def start_translate(self):\n",
    "        user_response = input(\"Hello - what do you want to translate to Spanish?\\n\")\n",
    "    \n",
    "        if user_response.lower() in self.negative_responses:\n",
    "            print(\"Ok, have a great day!\")\n",
    "            return\n",
    "    \n",
    "        #user_response = input('Great!')\n",
    "    \n",
    "        self.translate(user_response)\n",
    "  \n",
    "    def translate(self, reply):\n",
    "        while not self.make_exit(reply):\n",
    "            reply = input(self.generate_response(reply))\n",
    "    \n",
    "\n",
    "    def string_to_matrix(self, user_input):\n",
    "        tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "        user_input_matrix = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "        for timestep, token in enumerate(tokens):\n",
    "            if token in input_features_dict:\n",
    "                user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "\n",
    "        return user_input_matrix\n",
    "\n",
    "    def generate_response(self, user_input):\n",
    "        input_matrix = self.string_to_matrix(user_input)\n",
    "        states_value = encoder_model.predict(input_matrix)\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, target_features_dict['<START>']] = 1.0\n",
    "    \n",
    "        tran_response = ''\n",
    "\n",
    "        stop_condition = False\n",
    "\n",
    "        while not stop_condition:\n",
    "\n",
    "            output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "            tran_response += \" \" + sampled_token\n",
    "\n",
    "            if (sampled_token == '<END>' or len(tran_response) > max_decoder_seq_length):\n",
    "                stop_condition = True\n",
    "\n",
    "                target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "                target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "            if '<END>' in tran_response:\n",
    "                tran_response = tran_response.replace('<END>', '')\n",
    "\n",
    "            punctuations = [' ?', ' .', ' !', ' ,']            \n",
    "            for punctuation in punctuations:\n",
    "                if punctuation in tran_response:\n",
    "                    tran_response = tran_response.replace(punctuation, punctuation[-1])\n",
    "\n",
    "            states_value = [hidden_state, cell_state]\n",
    "\n",
    "        return tran_response\n",
    "  \n",
    "    def make_exit(self, reply):\n",
    "        for exit_command in self.exit_commands:\n",
    "            if exit_command in reply:\n",
    "                print(\"Ok, have a great day!\")\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hello - what do you want to translate to Spanish?\n",
      " Hi\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4b8c5f6254b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Translate!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtranslate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_translate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-029111134adf>\u001b[0m in \u001b[0;36mstart_translate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#user_response = input('Great!')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-029111134adf>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, reply)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_exit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-029111134adf>\u001b[0m in \u001b[0;36mgenerate_response\u001b[1;34m(self, user_input)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0minput_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mstates_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mtarget_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_decoder_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-029111134adf>\u001b[0m in \u001b[0;36mstring_to_matrix\u001b[1;34m(self, user_input)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstring_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"[\\w']+|[^\\s\\w]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0muser_input_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_encoder_seq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_encoder_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "# Translate!\n",
    "translate = Translator()\n",
    "translate.start_translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
